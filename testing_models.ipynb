{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZFtQvuQnSvFn3pRgfN/3q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smBello-tse/CIFAR10-classification/blob/main/testing_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31Ai-d5jBbgL"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "from time import time\n",
        "root = '/kaggle/input'\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading dataset\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "val_test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "_, test_dataset = torch.utils.data.random_split(val_test_dataset, [0.5, 0.5], generator=generator)"
      ],
      "metadata": {
        "id": "BjxwgSX7BjJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mean_std_dataset(dataset):\n",
        "  imgs = [item[0] for item in train_dataset] # item[0] and item[1] are image and its label\n",
        "  imgs = torch.stack(imgs, dim=0).numpy()\n",
        "\n",
        "# calculate mean over each channel (r,g,b)\n",
        "  mean_r = imgs[:,0,:,:].mean()\n",
        "  mean_g = imgs[:,1,:,:].mean()\n",
        "  mean_b = imgs[:,2,:,:].mean()\n",
        "  means = (mean_r,mean_g,mean_b)\n",
        "\n",
        "# calculate std over each channel (r,g,b)\n",
        "  std_r = imgs[:,0,:,:].std()\n",
        "  std_g = imgs[:,1,:,:].std()\n",
        "  std_b = imgs[:,2,:,:].std()\n",
        "  stds = (std_r,std_g,std_b)\n",
        "  return means, stds"
      ],
      "metadata": {
        "id": "pKfh8ZOsBvLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means_test, stds_test = compute_mean_std_dataset(test_dataset)"
      ],
      "metadata": {
        "id": "_h4QYZ3WCAbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(means_test, stds_test)])\n",
        "val_test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "_, test_dataset = torch.utils.data.random_split(val_test_dataset, [0.5, 0.5], generator=generator)"
      ],
      "metadata": {
        "id": "do0vXKLlB9I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataloader\n",
        "batch_size = 64\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, generator=generator)"
      ],
      "metadata": {
        "id": "eIEB3sxBCDgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = None"
      ],
      "metadata": {
        "id": "DBl_Y4t7CdTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "model.eval()\n",
        "print(\"Now testing...\")\n",
        "loss_test = 0\n",
        "test_batch = next(iter(test_loader))\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "with torch.no_grad():\n",
        "  for idx, (batch, target) in tqdm(enumerate(test_loader)):\n",
        "      batch, target = batch.to(device), target.to(device)\n",
        "      preds = model(batch)\n",
        "      loss = criterion(preds, target)\n",
        "      loss_test += loss.item()\n",
        "      all_preds.append(torch.argmax(preds, dim=-1).cpu().numpy())\n",
        "      all_targets.append(target.cpu().numpy())\n",
        "  all_preds = np.concatenate(all_preds)\n",
        "  all_targets = np.concatenate(all_targets)\n",
        "  loss_test /= len(test_loader)\n",
        "\n",
        "  print(f\"Loss_test: {loss_test:.4f}\")"
      ],
      "metadata": {
        "id": "H0uZFbp2CVl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"airplane (0)\", \"automobile (1)\", \"bird (2)\", \"cat (3)\", \"deer (4)\", \"dog (5)\", \"frog (6)\", \"horse (7)\", \"ship (8)\", \"truck (9)\"]\n",
        "#\n",
        "cm = confusion_matrix(all_targets, all_preds, labels=range(10))\n",
        "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "sns.heatmap(cm_df, annot=True, fmt=\"d\")"
      ],
      "metadata": {
        "id": "AXj0H8QcCfhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy score is: {accuracy_score(all_targets, all_preds)}\")"
      ],
      "metadata": {
        "id": "7kBbyOscCj-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_multi_class(y_true, y_pred, cm):\n",
        "  '''\n",
        "  y_true: true labels\n",
        "  y_pred: predicted labels\n",
        "  cm: confusion matrix\n",
        "\n",
        "  return list of accuracies for each classes\n",
        "  '''\n",
        "  accuracies = np.zeros((cm.shape[0],))\n",
        "  for i in range(cm.shape[0]):\n",
        "    accuracies[i] = cm[i,i] / np.sum(cm[i,:])\n",
        "  return accuracies\n",
        "\n",
        "accuracies = accuracy_multi_class(all_targets, all_preds, cm)\n",
        "accuracies_df = pd.DataFrame(accuracies, index=labels, columns=[\"Accuracy\"])\n",
        "accuracies_df = accuracies_df.sort_values(by=\"Accuracy\", ascending=False)\n",
        "print(accuracies_df)"
      ],
      "metadata": {
        "id": "2DdaZy4jCmV2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}